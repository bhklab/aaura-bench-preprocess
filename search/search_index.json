{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AAuRA Benchmark Preprocessing Authors: Katy Scott , Kaitlyn Kobayashi Contact: bhklab.katyscott@gmail.com Description: Preprocessing of datasets for use in the AAuRA Benchmarking tool. Set Up Prerequisites Pixi is required to run this project. If you haven't installed it yet, follow these instructions Installation Clone this repository to your local machine Navigate to the project directory Set up the environment using Pixi: pixi install Documentation Click here to view the full documentation.","title":"Home"},{"location":"#aaura-benchmark-preprocessing","text":"Authors: Katy Scott , Kaitlyn Kobayashi Contact: bhklab.katyscott@gmail.com Description: Preprocessing of datasets for use in the AAuRA Benchmarking tool.","title":"AAuRA Benchmark Preprocessing"},{"location":"#set-up","text":"","title":"Set Up"},{"location":"#prerequisites","text":"Pixi is required to run this project. If you haven't installed it yet, follow these instructions","title":"Prerequisites"},{"location":"#installation","text":"Clone this repository to your local machine Navigate to the project directory Set up the environment using Pixi: pixi install","title":"Installation"},{"location":"#documentation","text":"Click here to view the full documentation.","title":"Documentation"},{"location":"data_sources/","text":"Data Sources Overview This section should document all data sources used in your project. Proper documentation ensures reproducibility and helps others understand your research methodology. How to Document Your Data For each data source, include the following information: 1. External Data Sources Name : Official name of the dataset Version/Date : Version number or access date URL : Link to the data source Access Method : How the data was obtained (direct download, API, etc.) Access Date : When the data was accessed/retrieved Data Format : Format of the data (FASTQ, DICOM, CSV, etc.) Citation : Proper academic citation if applicable License : Usage restrictions and attribution requirements Example: ## TCGA RNA-Seq Data - **Name**: The Cancer Genome Atlas RNA-Seq Data - **Version**: Data release 28.0 - March 2021 - **URL**: https://portal.gdc.cancer.gov/ - **Access Method**: GDC Data Transfer Tool - **Access Date**: 2021-03-15 - **Citation**: The Cancer Genome Atlas Network. (2012). Comprehensive molecular portraits of human breast tumours. Nature, 490(7418), 61-70. - **License**: [NIH Genomic Data Sharing Policy](https://sharing.nih.gov/genomic-data-sharing-policy) 2. Internal/Generated Data Name : Descriptive name of the dataset Creation Date : When the data was generated Creation Method : Brief description of how the data was created Input Data : What source data was used Processing Scripts : References to scripts/Github Repo used to generate this data Example: ## Processed RNA-Seq Data - **Name**: Processed RNA-Seq Data for TCGA-BRCA - **Creation Date**: 2021-04-01 - **Creation Method**: Processed using kallisto and DESeq2 - **Input Data**: FASTQ Data obtained from the SRA database - **Processing Scripts**: [GitHub Repo](https://github.com/tcga-brca-rnaseq) 3. Data Dictionary For complex datasets, include a data dictionary that explains: Column Name Data Type Description Units Possible Values patient_id string Unique patient identifier N/A TCGA-XX-XXXX format age integer Patient age at diagnosis years 18-100 expression float Gene expression value TPM Any positive value Best Practices Store raw data in data/rawdata/ and never modify it Store processed data in data/procdata/ and all code used to generate it should be in workflow/scripts/ Document all processing steps Track data provenance (where data came from and how it was modified) Respect data usage agreements and licenses! This is especially important for data that should not be shared publicly","title":"Data Sources"},{"location":"data_sources/#data-sources","text":"","title":"Data Sources"},{"location":"data_sources/#overview","text":"This section should document all data sources used in your project. Proper documentation ensures reproducibility and helps others understand your research methodology.","title":"Overview"},{"location":"data_sources/#how-to-document-your-data","text":"For each data source, include the following information:","title":"How to Document Your Data"},{"location":"data_sources/#1-external-data-sources","text":"Name : Official name of the dataset Version/Date : Version number or access date URL : Link to the data source Access Method : How the data was obtained (direct download, API, etc.) Access Date : When the data was accessed/retrieved Data Format : Format of the data (FASTQ, DICOM, CSV, etc.) Citation : Proper academic citation if applicable License : Usage restrictions and attribution requirements Example: ## TCGA RNA-Seq Data - **Name**: The Cancer Genome Atlas RNA-Seq Data - **Version**: Data release 28.0 - March 2021 - **URL**: https://portal.gdc.cancer.gov/ - **Access Method**: GDC Data Transfer Tool - **Access Date**: 2021-03-15 - **Citation**: The Cancer Genome Atlas Network. (2012). Comprehensive molecular portraits of human breast tumours. Nature, 490(7418), 61-70. - **License**: [NIH Genomic Data Sharing Policy](https://sharing.nih.gov/genomic-data-sharing-policy)","title":"1. External Data Sources"},{"location":"data_sources/#2-internalgenerated-data","text":"Name : Descriptive name of the dataset Creation Date : When the data was generated Creation Method : Brief description of how the data was created Input Data : What source data was used Processing Scripts : References to scripts/Github Repo used to generate this data Example: ## Processed RNA-Seq Data - **Name**: Processed RNA-Seq Data for TCGA-BRCA - **Creation Date**: 2021-04-01 - **Creation Method**: Processed using kallisto and DESeq2 - **Input Data**: FASTQ Data obtained from the SRA database - **Processing Scripts**: [GitHub Repo](https://github.com/tcga-brca-rnaseq)","title":"2. Internal/Generated Data"},{"location":"data_sources/#3-data-dictionary","text":"For complex datasets, include a data dictionary that explains: Column Name Data Type Description Units Possible Values patient_id string Unique patient identifier N/A TCGA-XX-XXXX format age integer Patient age at diagnosis years 18-100 expression float Gene expression value TPM Any positive value","title":"3. Data Dictionary"},{"location":"data_sources/#best-practices","text":"Store raw data in data/rawdata/ and never modify it Store processed data in data/procdata/ and all code used to generate it should be in workflow/scripts/ Document all processing steps Track data provenance (where data came from and how it was modified) Respect data usage agreements and licenses! This is especially important for data that should not be shared publicly","title":"Best Practices"},{"location":"devnotes/","text":"Developer Notes Removing COVID-19 CT Lung from analysis 2026-01-07 We chose to remove these samples from analysis as they do not have tumours present and only include a small number of samples. Did not include them in the dataset_anatomy_match.csv we made. Column setup for aaura index and med-imagetools processing 2026-01-07 For datasets that have been processed by med-imagetools, we will take in the index-simple.csv and extract the subset of columns we use for the aaura index. Columns that will need to be calculated in addition are: annotation_type annotation_coords largest_slice_index lesion_location source (Optional, mostly used for datasets composed of multiple other datasets) Mask indexing for saving starting at 1 to reflect labels 2026-01-07 Starting the mask labelling at 1 to reflect the voxel values they were in the original image. 0 is reserved for background. Add option to append new processed dataset index to existing index 2026-01-08 Today's solution chosen for handling what to do if processing new data but you want to preserve the already processed data. append_index argument can be set such that an existing index file will be loaded in, the new processed data index will be concatenated to the end, checked for duplicates, sorted, and then saved. For duplicate checking, the new processed data entry will be kept. This way, if processing a dataset breaks in the middle, can update the metadata file with what data to process. Didn't want to implement image existence checking yet. mit_to_aaura_index setup for datasets 2026-01-12 HCC-TACE-Seg datasource = \"TCIA\" dataset = \"HCC-TACE-Seg\" ROI_key = \"Mass\" image_modality = \"CT\" mask_modality = [\"SEG\"] lesion_location = \"abdomen\" 4D-Lung datasource = \"TCIA\" dataset = \"4D-Lung\" ROI_key = \"Tumor_\" image_modality = \"CT\" mask_modality = [\"RTSTRUCT\"] lesion_location = \"abdomen\" RIDER-LungCT-Seg datasource = \"TCIA\" dataset = \"RIDER-LungCT-Seg\" ROI_key = \"GTVp|Neoplasm\" image_modality = \"CT\" mask_modality = [\"SEG\",\"RTSTRUCT\"] lesion_location = \"abdomen\" RADCURE * Using mit_RADCURE_windowed datasource = \"TCIA\" dataset = \"RADCURE\" ROI_key = \"GTVp\" image_modality = \"CT\" mask_modality = [\"RTSTRUCT\"] # THIS HAS TO BE A LIST lesion_location = \"headneck\" special_prefix = \"OCSCC_\" special_suffix = \"_windowed\"","title":"Developer Notes"},{"location":"devnotes/#developer-notes","text":"","title":"Developer Notes"},{"location":"devnotes/#removing-covid-19-ct-lung-from-analysis","text":"2026-01-07 We chose to remove these samples from analysis as they do not have tumours present and only include a small number of samples. Did not include them in the dataset_anatomy_match.csv we made.","title":"Removing COVID-19 CT Lung from analysis"},{"location":"devnotes/#column-setup-for-aaura-index-and-med-imagetools-processing","text":"2026-01-07 For datasets that have been processed by med-imagetools, we will take in the index-simple.csv and extract the subset of columns we use for the aaura index. Columns that will need to be calculated in addition are: annotation_type annotation_coords largest_slice_index lesion_location source (Optional, mostly used for datasets composed of multiple other datasets)","title":"Column setup for aaura index and med-imagetools processing"},{"location":"devnotes/#mask-indexing-for-saving-starting-at-1-to-reflect-labels","text":"2026-01-07 Starting the mask labelling at 1 to reflect the voxel values they were in the original image. 0 is reserved for background.","title":"Mask indexing for saving starting at 1 to reflect labels"},{"location":"devnotes/#add-option-to-append-new-processed-dataset-index-to-existing-index","text":"2026-01-08 Today's solution chosen for handling what to do if processing new data but you want to preserve the already processed data. append_index argument can be set such that an existing index file will be loaded in, the new processed data index will be concatenated to the end, checked for duplicates, sorted, and then saved. For duplicate checking, the new processed data entry will be kept. This way, if processing a dataset breaks in the middle, can update the metadata file with what data to process. Didn't want to implement image existence checking yet.","title":"Add option to append new processed dataset index to existing index"},{"location":"devnotes/#mit_to_aaura_index-setup-for-datasets","text":"2026-01-12 HCC-TACE-Seg datasource = \"TCIA\" dataset = \"HCC-TACE-Seg\" ROI_key = \"Mass\" image_modality = \"CT\" mask_modality = [\"SEG\"] lesion_location = \"abdomen\" 4D-Lung datasource = \"TCIA\" dataset = \"4D-Lung\" ROI_key = \"Tumor_\" image_modality = \"CT\" mask_modality = [\"RTSTRUCT\"] lesion_location = \"abdomen\" RIDER-LungCT-Seg datasource = \"TCIA\" dataset = \"RIDER-LungCT-Seg\" ROI_key = \"GTVp|Neoplasm\" image_modality = \"CT\" mask_modality = [\"SEG\",\"RTSTRUCT\"] lesion_location = \"abdomen\" RADCURE * Using mit_RADCURE_windowed datasource = \"TCIA\" dataset = \"RADCURE\" ROI_key = \"GTVp\" image_modality = \"CT\" mask_modality = [\"RTSTRUCT\"] # THIS HAS TO BE A LIST lesion_location = \"headneck\" special_prefix = \"OCSCC_\" special_suffix = \"_windowed\"","title":"mit_to_aaura_index setup for datasets"},{"location":"usage/","text":"Usage Guide Project Configuration TODO:: discuss how to edit the configuration files in the config/ directory to match your research parameters TODO:: discuss how to add your input data to the data/rawdata/ directory and document it properly in the docs/data_sources/ directory TODO:: discuss how to manage and organize your data sources effectively Running Your Analysis TODO:: discuss using pixi tasks to run the analysis","title":"Usage"},{"location":"usage/#usage-guide","text":"","title":"Usage Guide"},{"location":"usage/#project-configuration","text":"TODO:: discuss how to edit the configuration files in the config/ directory to match your research parameters TODO:: discuss how to add your input data to the data/rawdata/ directory and document it properly in the docs/data_sources/ directory TODO:: discuss how to manage and organize your data sources effectively","title":"Project Configuration"},{"location":"usage/#running-your-analysis","text":"TODO:: discuss using pixi tasks to run the analysis","title":"Running Your Analysis"}]}